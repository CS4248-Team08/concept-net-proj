{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bbb1baea-6ffb-4360-b066-db5208a1beea",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "30e8220b",
    "execution_start": 1648990897462,
    "execution_millis": 358,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 112.1875
   },
   "source": "!nvidia-smi",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "/bin/sh: 1: nvidia-smi: not found\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8782f65b-7fa2-41ab-af62-208e7d77b6a8",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3913,
    "execution_start": 1648990897827,
    "gradient": {
     "editing": true,
     "id": "9276c4c5-f974-41ed-a094-fca95a26f813",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "b6b7828f",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 438.375
   },
   "source": "import os\nimport pickle\n\nimport numpy as np\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\n\nfrom transformers import BertTokenizer, BertModel\n\nfrom tqdm import tqdm",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "62c21251-0d38-437b-9824-58165e7e1297",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1648990901745,
    "gradient": {
     "editing": false,
     "id": "4e1d5978-b6c9-4325-9465-a702bb216bd6",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "c9b07865",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "np.random.seed(42)\n\nEPOCHS = 20\nBATCH_SIZE = 16\nLR = 1e-6",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Load Data",
   "metadata": {
    "cell_id": "00002-237bd513-7ef7-4281-a517-334c886ebec0",
    "gradient": {
     "editing": false,
     "id": "1e2a904f-daca-4fa7-8efa-abac3e4422cb",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "351d5abf-84d3-4c51-bfc7-24b13b7e8143",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 51,
    "execution_start": 1648990901787,
    "gradient": {
     "editing": false,
     "id": "e3add54d-4830-4852-955a-9598444a7a68",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "e07a89d6",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "paths = pickle.load(open('data/science/paths.pkl', 'rb'))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "ec0bc867-20b2-4028-bbf7-2b17c345b782",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 94,
    "execution_start": 1648990901855,
    "gradient": {
     "editing": false,
     "id": "f6c60131-18bf-4e9b-92dd-3e4bd3dfd8cf",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "126ea0db",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "def ff(path_str):\n    id = path_str[:-1]\n    if path_str[-1] == 'r':\n        return paths[id]['reverse']\n    else:\n        return paths[id]['forward']\ndef fff(ans):\n    paths_str = ans.split('_')\n    return {\n        'A': ff(paths_str[0]),\n        'B': ff(paths_str[1]),\n        'better': 'A' if paths_str[2] == paths_str[0] else 'B'\n    }\n    return list(map(ff, paths_str))\nwith open('data/science/answers.txt', 'r') as f:\n    answers = list(map(fff, filter(lambda x: len(x) > 0, f.read().split('\\n'))))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8c3e0678-87de-4a93-9b91-663842bebf33",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1648990901957,
    "gradient": {
     "editing": false,
     "id": "e0a784e0-d4e4-44d8-a0e9-1212dc54a4e2",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "f46e5888",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 137.375,
    "deepnote_output_heights": [
     40.375
    ]
   },
   "source": "answers[0]['A']",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 6,
     "data": {
      "text/plain": "{'text': 'Piece is a type of Part. Part is related to Car. you are likely to find Car in/at/on Land. ',\n 'short': 'Piece --IsA--> Part <--RelatedTo--> Car --AtLocation--> Land '}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1943a4af-6c46-46b8-95ec-36ac46a3edb5",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 233896,
    "execution_start": 1648990902018,
    "gradient": {
     "editing": false,
     "id": "2c7df0c3-d118-4194-afe3-382432d0bdb5",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "35f8b13",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 137.375,
    "deepnote_output_heights": [
     40.375
    ]
   },
   "source": "answers[0]['B']",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 7,
     "data": {
      "text/plain": "{'text': 'Dream is related to Day. Day is related to Measurement. Measurement is related to Year. ',\n 'short': 'Dream <--RelatedTo--> Day <--RelatedTo--> Measurement <--RelatedTo--> Year '}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "89df3884-2b58-4170-b855-821474efa412",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1648990902019,
    "gradient": {
     "editing": false,
     "id": "09d8c53f-fcc8-42fb-b79d-bbcff8ee6872",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "f1ec5baa",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 118.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "answers[0]['better']",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "'A'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-61970236-4f56-4876-81c0-ae4fb356b2a8",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1648990902061,
    "gradient": {
     "editing": false,
     "id": "f2a6ab46-82b7-45ce-9a95-6d86939c11e2",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "a8ad987",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 423
   },
   "source": "text_arr = []\nlabel_arr = []\n\nfor ans in answers:\n#     text_arr.append(ans['A']['text'])\n#     text_arr.append(ans['B']['text'])\n#     if ans['better'] == 'A':\n#         label_arr.append(1)\n#         label_arr.append(0)\n#     else:\n#         label_arr.append(0)\n#         label_arr.append(1)\n    text_arr.append(ans['A']['text'] + ans['B']['text'])\n    text_arr.append(ans['B']['text'] + ans['A']['text'])\n    if ans['better'] == 'A':\n        label_arr.append(1)\n        label_arr.append(0)\n    else:\n        label_arr.append(0)\n        label_arr.append(1)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e5bc2d7b-e44c-4e68-b651-3044f491f6ab",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1648990902141,
    "gradient": {
     "editing": false,
     "id": "aa325883-6955-4acc-896e-70d0855663ae",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "7d52dc2c",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 135
   },
   "source": "data_df = pd.DataFrame(data={\n    'Text': text_arr,\n    'Label': label_arr,\n})",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b6566973-d484-4bb9-9bf0-409ac54cbbab",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1648990902186,
    "gradient": {
     "editing": false,
     "id": "109cf289-05de-4978-870c-82db2d9f5d25",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "39b36e92",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 148.1875
   },
   "source": "train_df, val_df, test_df = np.split(data_df.sample(frac=1, random_state=42), [int(.8*len(data_df)), int(.9*len(data_df))])\n\nprint(len(train_df),len(val_df), len(test_df))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "22080 2760 2760\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-6025089b-48bd-4a3f-a53c-51857f9140da",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 391,
    "execution_start": 1648990902230,
    "gradient": {
     "editing": false,
     "id": "04a93fc2-e649-4839-a48f-0208f225dc53",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "da3c9165",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 567
   },
   "source": "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, text_col='Text', label_col='Label'):\n        self.labels = [float(x) for x in df[label_col]]\n        self.texts = [\n            tokenizer(\n                text, \n                padding='max_length',\n                max_length = 512,\n                truncation=True,\n                return_tensors='pt'\n            ) for text in df[text_col]\n        ]\n    def classes(self):\n        return self.labels\n    def __len__(self):\n        return len(self.labels)\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n    def __getitem__(self, idx):\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n        return batch_texts, batch_y",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Model",
   "metadata": {
    "cell_id": "00006-925b51ab-b75c-4575-ac37-7478b205f33e",
    "gradient": {
     "editing": false,
     "id": "89548466-2055-49a7-b626-9d4bbf55380d",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-faf773ca-da6f-484d-9a6a-df349bcac434",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1648990902640,
    "gradient": {
     "editing": false,
     "id": "07033b95-6d54-457c-bbae-3d41abcf0091",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "6cafba65",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "class BertClassifier(nn.Module):\n    def __init__(self, dropout=0.5):\n        super(BertClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        # for param in self.bert.parameters():\n        #     param.requires_grad = False\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 1)\n        self.activation = nn.Sigmoid()\n    def forward(self, input_id, mask):\n        _, x = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        x = self.dropout(x)\n        x = self.linear(x)\n        x = self.activation(x)\n        return x",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Training",
   "metadata": {
    "cell_id": "00008-53e750a0-f079-4aea-93be-bcd66853309e",
    "gradient": {
     "editing": false,
     "id": "a868aba9-f451-43a9-bb7d-4e73174f0878",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-89e946cb-b674-461b-bba1-af467f7e6c6d",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1648990902675,
    "gradient": {
     "editing": false,
     "id": "d233a8bf-0d2e-4915-a69b-58dfdd8c3f91",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "20170310",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 837
   },
   "source": "def train(model, train_data, val_data, learning_rate, epochs):\n    train, val = Dataset(train_data), Dataset(val_data)\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    criterion = nn.BCELoss()\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n    if use_cuda:\n            model = model.cuda()\n            criterion = criterion.cuda()\n    for epoch_num in range(epochs):\n            total_acc_train = 0\n            total_loss_train = 0\n            model.train()\n            for train_input, train_label in tqdm(train_dataloader):\n                train_label = train_label.to(device).unsqueeze(1)\n                mask = train_input['attention_mask'].to(device)\n                input_id = train_input['input_ids'].squeeze(1).to(device)\n                output = model(input_id, mask)\n                batch_loss = criterion(output.double(), train_label)\n                total_loss_train += batch_loss.item()\n                acc = (output.round() == train_label).sum().item()\n                total_acc_train += acc\n                model.zero_grad()\n                batch_loss.backward()\n                optimizer.step()\n            total_acc_val = 0\n            total_loss_val = 0\n            model.eval()\n            with torch.no_grad():\n                for val_input, val_label in val_dataloader:\n                    val_label = val_label.to(device).unsqueeze(1)\n                    mask = val_input['attention_mask'].to(device)\n                    input_id = val_input['input_ids'].squeeze(1).to(device)\n                    output = model(input_id, mask)\n                    batch_loss = criterion(output.double(), val_label)\n                    total_loss_val += batch_loss.item()\n                    acc = (output.round() == val_label).sum().item()\n                    total_acc_val += acc\n            print(\n                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n            torch.save(model.state_dict(), 'bert_clf.pt')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-e0e8e963-621c-47b4-9352-545544d3da93",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 45,
    "execution_start": 1648990902761,
    "gradient": {
     "editing": false,
     "id": "4592d958-6b23-4d55-a2bc-60b5d43120e3",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "20f491bd",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 639
   },
   "source": "def evaluate(model, test_data):\n    test = Dataset(test_data)\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE)\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    if use_cuda:\n        model = model.cuda()\n    y_pred_list = []\n    y_test = []\n    # global output_rnd\n    # global test_lbl\n    model.eval()\n    with torch.no_grad():\n        for test_input, test_label in test_dataloader:\n            test_label = test_label.to(device).unsqueeze(1)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n            output = model(input_id, mask)\n            # output_rnd = output.round()\n            # test_lbl = test_label\n            # return\n            y_pred_list.append(output.round().cpu().numpy())\n            y_test.append(test_label.cpu().numpy())\n    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n    y_pred_list = [item for sublist in y_pred_list for item in sublist]\n    y_test = [a.squeeze().tolist() for a in y_test]\n    y_test = [item for sublist in y_test for item in sublist]\n    cm = confusion_matrix(y_test, y_pred_list)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot()\n    plt.show()\n    print(classification_report(y_test, y_pred_list))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ...",
   "metadata": {
    "cell_id": "00011-848979d0-21ec-4e99-8f05-d12dd793d4cc",
    "gradient": {
     "editing": false,
     "id": "6fa1a893-b2d2-4352-b78c-f401cb9e8582",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-b1b6d392-fb8b-4ccb-803e-dc64d8a5dc31",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2355,
    "execution_start": 1648990902806,
    "gradient": {
     "editing": false,
     "id": "56f2cfa7-7241-49f6-b1c8-b0122fdfb36e",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "4e226140",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 719
   },
   "source": "model = BertClassifier()\nprint(model)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nBertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.5, inplace=False)\n  (linear): Linear(in_features=768, out_features=1, bias=True)\n  (activation): Sigmoid()\n)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9dc7d004319b45508d8a062cc524110d",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "11ccdc9",
    "execution_start": 1648990905169,
    "execution_millis": 1806,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 118.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "model.load_state_dict(torch.load('bert_clf_e20.pt', map_location=torch.device('cpu')))",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 17,
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "62cf249680fe4f5dbe2c3d0dd4c0a7e8",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 47,
    "execution_start": 1648990906978,
    "gradient": {
     "editing": false,
     "id": "de7f805e-eddc-494e-bc80-ba929d805e5c",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "c0608af3",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "# train(model, train_df, val_df, LR, EPOCHS)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00014-0a1abd85-cc21-4e45-a2a1-467d46300b02",
    "deepnote_to_be_reexecuted": false,
    "gradient": {
     "editing": false,
     "id": "29c624e0-180e-4b32-bacd-d32927159151",
     "kernelId": "bdad9f9f-f07c-45e1-9f7d-b89ce0615e8e"
    },
    "source_hash": "1eb40e64",
    "execution_start": 1648990907201,
    "execution_millis": 18650567,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 568.6875,
    "deepnote_output_heights": [
     264
    ]
   },
   "source": "y = evaluate(model, test_df)",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 312,
       "height": 262
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n         0.0       0.68      0.71      0.69      1347\n         1.0       0.71      0.69      0.70      1413\n\n    accuracy                           0.70      2760\n   macro avg       0.70      0.70      0.70      2760\nweighted avg       0.70      0.70      0.70      2760\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8bb8e57208a346e38b10b7ea4ce4cb29",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ae8bd3f4-1eb1-4931-aeae-03a910b193bc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "64a7e9c7-9718-4e06-8a2c-305103501537",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 }
}